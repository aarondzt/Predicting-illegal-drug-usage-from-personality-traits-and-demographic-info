{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting illegal drug usage from personality traits and demographic info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "Understanding the personality traits that are predictive of illegal drug usage is important for public health and guidence of policy-making. In [Fehrman et al.](https://arxiv.org/abs/1506.06297), the authors collect survey data on demographic factors, personality traits, and drug usage, and then run several machine learning models to analyze the traits that are predictive of the usage of individual and clusters of drugs. In this project, I focused on individuals who have used drugs that are widely classified as illegal (mushrooms, ecstasy, cocaine, LSD, ketamine, heroin, and crack) at least once. Very few people will take any one of these drugs in their lifetime, so the type of person who would cross that threshold would be interesting to understand.\n",
    "\n",
    "I ran logistic regression and decision tree classifier models, which exhibited similar test accuracy (~70%) to the models described in the paper. The logistic regression model demonstrated that the personality traits of sensation seeking and openness to experience, in addition to the demographic of men were the most predictive of illegal drug use. The decision tree classifier demonstrated that a branch of lower sensation seeking, lower openness, and higher conscientiousness was the most predictive of never using an illegal drug."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "The authors of the paper collected survey data on five demographic factors (age, gender, education, country, ethnicity) and seven personality traits (neuroticism, extraversion, openness to experience, agreeableness, conscientiousness from the [Five Factor Model](https://www.annualreviews.org/doi/abs/10.1146/annurev.ps.41.020190.002221), and impulsivity and sensation seeking from two other personlity inventories). The Five Factor model is a well-validated metric of personality that has shown to be predictive of real-world outcomes in many studies. The impulsivity and sensation seeking metrics are specifically tailored to capture traits known to be associated with drug use. In addition to this, the authors collected data on the usage of 16 psychoactive substances (alcohol, amphetamines, amyl nitrite, benzodiazepines, caffeine, cannabis, cocaine, crack, ecstasy, heroin, ketamine, legal highs, LSD, methadone, mushrooms, nicotine, volatile substances), plus two controls (chocolate and a fictitious substance called semer). In the dataset provided by the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Drug+consumption+%28quantified%29), each feature was quantified and mean-centered. Some features were ordinal such as age (from bracket \"18-24\" to \"65+\"), education (from \n",
    "\"Left school before 16 years\" to \"Doctorate\"), and drug use (one of seven responses from \"Never used\" to \"Used in the last day.\" Other features, such as country and ethnicity, were quantified, although the quantification is neccessarily arbitrary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related work and motivation\n",
    "Related studies have used this dataset to examine features predictive of [alcohol](https://link.springer.com/article/10.1007/s41870-018-0094-3) and [volatile substance](https://ieeexplore.ieee.org/abstract/document/8234516) abuse. In this project, I decided not to focus on a single drug, but the usage of drugs that are widely classified as illegal. I also decided not to focus on when/how often drugs are used, but simply on if an individual used an illegal drug at least once. That is, I excluded legal drugs (alcohol, caffeine, cannabis, and nicotine), prescription drugs (amphetamines, benzodiazepines, and methadone), and drugs of little public interest (amyl nitrite, legal highs, and volatile substances). This leaves mushrooms, ecstasy, cocaine, LSD, ketamine, heroin, and crack as my drugs of interest. Ultimately, the question was: What demographic factors and personality traits are predicative of choosing to use an illegal drug in one's lifetime?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods 1.1 Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1885, 31)\n"
     ]
    }
   ],
   "source": [
    "# Read csv\n",
    "import pandas as pd\n",
    "csv = pd.read_csv('Data/Drugs.csv', header = None)\n",
    "print(csv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "# Name columns\n",
    "columns = ['Age', 'Female', 'Education', 'Country', 'Ethnicity', \\\n",
    "           'Neuroticism', 'Extraversion', 'Openness', 'Agreeableness', 'Conscientiousness', \\\n",
    "           'Impulsivity', 'SensationSeeking', \\\n",
    "           'Alcohol', 'Amphetamines', 'AmylNitrite', 'Benzodiazepines', 'Caffeine', 'Cannabis', 'Chocolate', \\\n",
    "           'Cocaine', 'Crack', 'Ecstasy', 'Heroin', 'Ketamine', 'LegalHighs', 'LSD', 'Methadone', 'Mushrooms', \\\n",
    "           'Nicotine', 'Semer', 'VolatileSubstances']\n",
    "print(len(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "data = pd.DataFrame(data = csv)\n",
    "data.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods 1.2 Data cleaning, manipulation, and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop multi-category, non-ordinal features\n",
    "data = data.drop(['Country', 'Ethnicity'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1877\n",
      "2       3\n",
      "3       2\n",
      "1       2\n",
      "4       1\n",
      "Name: Semer, dtype: int64\n",
      "(1885, 29)\n",
      "(1877, 29)\n"
     ]
    }
   ],
   "source": [
    "# Check value count for Semer, a fictitious drug included to weed out participants responding improperly\n",
    "print(data.Semer.value_counts())\n",
    "print(data.shape)\n",
    "# Remove these rows\n",
    "data = data[data['Semer'] == 0]\n",
    "print(data.shape)\n",
    "# Drop semer column\n",
    "data = data.drop('Semer', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name drug columns\n",
    "drug_columns = ['Alcohol', 'Amphetamines', 'AmylNitrite', 'Benzodiazepines', 'Caffeine', 'Cannabis', 'Chocolate', \\\n",
    "           'Cocaine', 'Crack', 'Ecstasy', 'Heroin', 'Ketamine', 'LegalHighs', 'LSD', 'Methadone', 'Mushrooms', \\\n",
    "           'Nicotine', 'VolatileSubstances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert drug use to binary (1 = used, 0 = never used)\n",
    "for column in drug_columns:\n",
    "    data[column].values[data[column].values > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot demographic histograms\n",
    "import matplotlib.pyplot as plt\n",
    "histograms = data[['Age', 'Female', 'Education']].hist(bins = 6, figsize = (5, 5))\n",
    "plt.savefig('Images/personality_histograms.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[\"Normality of predictors is not an assumption of logistic regression, or linear regression for that matter\"](\n",
    "https://stats.stackexchange.com/questions/72400/whether-to-transform-non-normal-independent-variables-in-logistic-regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot personality histograms\n",
    "histograms = data[['Neuroticism', 'Extraversion', 'Openness', 'Agreeableness', 'Conscientiousness', \\\n",
    "           'Impulsivity', 'SensationSeeking']].hist(bins = 10, figsize = (10, 10))\n",
    "plt.savefig('Images/personality_histograms.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug</th>\n",
       "      <th>% used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caffeine</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alcohol</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chocolate</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cannabis</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nicotine</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amphetamines</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mushrooms</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benzodiazepines</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ecstasy</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cocaine</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LSD</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LegalHighs</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AmylNitrite</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Methadone</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>VolatileSubstances</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ketamine</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Heroin</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Crack</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Drug  % used\n",
       "4             Caffeine    0.99\n",
       "0              Alcohol    0.98\n",
       "6            Chocolate    0.98\n",
       "5             Cannabis    0.78\n",
       "16            Nicotine    0.77\n",
       "1         Amphetamines    0.48\n",
       "15           Mushrooms    0.48\n",
       "3      Benzodiazepines    0.47\n",
       "9              Ecstasy    0.46\n",
       "7              Cocaine    0.45\n",
       "13                 LSD    0.43\n",
       "12          LegalHighs    0.42\n",
       "2          AmylNitrite    0.31\n",
       "14           Methadone    0.24\n",
       "17  VolatileSubstances    0.23\n",
       "11            Ketamine    0.21\n",
       "10              Heroin    0.15\n",
       "8                Crack    0.14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank by usage\n",
    "usage_list = []\n",
    "for column in drug_columns:\n",
    "    usage_list.append(data[column].mean())\n",
    "usage_df = pd.DataFrame(columns = ['Drug', '% used'])\n",
    "usage_df['Drug'] = drug_columns\n",
    "usage_df['% used'] = usage_list\n",
    "round(usage_df, 2).sort_values('% used', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mushrooms          0.48\n",
       "Ecstasy            0.46\n",
       "Cocaine            0.45\n",
       "LSD                0.43\n",
       "Ketamine           0.21\n",
       "Heroin             0.15\n",
       "Crack              0.14\n",
       "UsedIllegalDrug    0.64\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create column for participants who have used one or more illegal drugs\n",
    "pd.options.mode.chained_assignment = None\n",
    "illegal_drugs = ['Mushrooms', 'Ecstasy', 'Cocaine', 'LSD', 'Ketamine', 'Heroin', 'Crack']\n",
    "illegal_drugs_df = data[illegal_drugs]\n",
    "illegal_drugs_df['UsedIllegalDrug'] = illegal_drugs_df.sum(axis = 1)\n",
    "# If the sum of single use of any illegal drug > 0, then UsedIllegalDrug = 1\n",
    "illegal_drugs_df['UsedIllegalDrug'][illegal_drugs_df['UsedIllegalDrug'] > 0] = 1\n",
    "# Percent of participants who have used each drug at least once \n",
    "# + percent of participants who have used one or more of these drugs at least once\n",
    "round(illegal_drugs_df.mean(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "64% of individuals have used one of these illegal drugs. Can I create a model that performs better than 64% (a dummy model)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column to main data\n",
    "data['UsedIllegalDrug'] = illegal_drugs_df['UsedIllegalDrug']\n",
    "# Drop columns not of interest\n",
    "data_illegaldrugs = data[['Age', 'Female', 'Education', 'Neuroticism', 'Extraversion', 'Openness', 'Agreeableness', \\\n",
    "            'Conscientiousness', 'Impulsivity', 'SensationSeeking', 'UsedIllegalDrug']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Female</th>\n",
       "      <th>Education</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Impulsivity</th>\n",
       "      <th>SensationSeeking</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UsedIllegalDrug</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Age  Female  Education  Neuroticism  Extraversion  Openness  \\\n",
       "UsedIllegalDrug                                                                 \n",
       "0                0.33    0.17       0.20        -0.15          0.03     -0.46   \n",
       "1               -0.13   -0.09      -0.12         0.08         -0.02      0.25   \n",
       "\n",
       "                 Agreeableness  Conscientiousness  Impulsivity  \\\n",
       "UsedIllegalDrug                                                  \n",
       "0                         0.21               0.35        -0.38   \n",
       "1                        -0.12              -0.20         0.22   \n",
       "\n",
       "                 SensationSeeking  \n",
       "UsedIllegalDrug                    \n",
       "0                           -0.54  \n",
       "1                            0.30  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by illegal drug use\n",
    "grouped = round(data_illegaldrugs.groupby('UsedIllegalDrug').mean(), 2)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SensationSeeking    -0.84\n",
       "Openness            -0.71\n",
       "Impulsivity         -0.60\n",
       "Neuroticism         -0.23\n",
       "Extraversion         0.05\n",
       "Female               0.26\n",
       "Education            0.32\n",
       "Agreeableness        0.33\n",
       "Age                  0.46\n",
       "Conscientiousness    0.55\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate largest differences in features between groups\n",
    "difference = grouped.iloc[0] - grouped.iloc[1]\n",
    "difference.sort_values()\n",
    "# Non-users are less sensation seeking, more consciousness, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Impulsivity</th>\n",
       "      <th>SensationSeeking</th>\n",
       "      <th>UsedIllegalDrug</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-0.48246</th>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.48246</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Age  Education  Neuroticism  Extraversion  Openness  Agreeableness  \\\n",
       "Female                                                                          \n",
       "-0.48246 -0.06      -0.19        -0.07         -0.06      0.13          -0.22   \n",
       " 0.48246  0.13       0.19         0.07          0.06     -0.14           0.22   \n",
       "\n",
       "          Conscientiousness  Impulsivity  SensationSeeking  UsedIllegalDrug  \n",
       "Female                                                                       \n",
       "-0.48246              -0.18         0.17              0.23             0.76  \n",
       " 0.48246               0.18        -0.16             -0.24             0.51  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by gender\n",
    "grouped = round(data_illegaldrugs.groupby('Female').mean(), 2)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agreeableness       -0.44\n",
       "Education           -0.38\n",
       "Conscientiousness   -0.36\n",
       "Age                 -0.19\n",
       "Neuroticism         -0.14\n",
       "Extraversion        -0.12\n",
       "UsedIllegalDrug      0.25\n",
       "Openness             0.27\n",
       "Impulsivity          0.33\n",
       "SensationSeeking     0.47\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate largest differences in features between groups\n",
    "difference = grouped.iloc[0] - grouped.iloc[1]\n",
    "difference.sort_values()\n",
    "# Men are less agreeable, less educated, more impulsive, more sensation seeking, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features from target\n",
    "X = data_illegaldrugs.drop('UsedIllegalDrug', axis = 1)\n",
    "y = data_illegaldrugs['UsedIllegalDrug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SensationSeeking</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Impulsivity</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extraversion</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Openness</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Education</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Features  VIF\n",
       "9   SensationSeeking  2.1\n",
       "8        Impulsivity  1.8\n",
       "3        Neuroticism  1.5\n",
       "4       Extraversion  1.5\n",
       "7  Conscientiousness  1.5\n",
       "5           Openness  1.3\n",
       "1             Female  1.2\n",
       "6      Agreeableness  1.2\n",
       "2          Education  1.1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine multicollinearity\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif = pd.DataFrame(columns = ['Features', 'VIF'])\n",
    "vif['Features'] = X.columns\n",
    "for i in range(X.shape[1]):\n",
    "    vif.loc[i, 'VIF'] = variance_inflation_factor(X.values, i).round(1)\n",
    "# Remove constant row\n",
    "vif = vif[1:]\n",
    "# Sort by VIF\n",
    "vif.sort_values('VIF', ascending = False)\n",
    "# No VIF > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1501, 10)\n",
      "(376, 10)\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 20201011, stratify = y)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods 2.1 Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data, you must scale if using regularization \n",
    "# so that all your coefficients are on the same scale before shrinkage\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "columns = X_train.columns\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search\n",
    "# If N >> P, F1 is a better metric\n",
    "# If P >> N, balanced accuracy is a better metric\n",
    "# Scoring = balanced accuracy because target is inbalanced (64% users, P >> N)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "grid = {'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'penalty' :['elasticnet'], 'solver': ['saga'], \n",
    "        'l1_ratio': [0, 0.2, 0.4, 0.6, 0.8, 1], 'class_weight': ['balanced', None]}\n",
    "gridsearch = GridSearchCV(estimator = logreg, param_grid = grid, n_jobs = -1,                      \n",
    "                          cv = 10, return_train_score = True, scoring = 'balanced_accuracy')\n",
    "gridsearch.fit(X_train, y_train)\n",
    "logreg_models = pd.DataFrame(gridsearch.cv_results_).sort_values('mean_test_score', ascending = False)\n",
    "print('LR mean test score:', round(logreg_models['mean_test_score'].iloc[0], 3))\n",
    "print('LR mest parameters', logreg_models['params'].iloc[0]) # Best parameters, 0% lasso regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with best paraeters\n",
    "logreg = LogisticRegression(C = 0.05,\n",
    " class_weight = 'balanced',\n",
    " l1_ratio = 0,\n",
    " penalty = 'elasticnet',\n",
    " solver = 'saga')\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort features by beta value\n",
    "feature_coefs = pd.DataFrame(columns = ['Feature', 'Beta'])\n",
    "feature_coefs['Feature'] = columns\n",
    "coefs = logreg.coef_.round(2)\n",
    "feature_coefs['Beta'] = coefs[0]\n",
    "feature_coefs.sort_values('Beta')\n",
    "# Sensation seeking and openness are the two largest beta values that are associated with being an illegal drug user\n",
    "# After that, the next two largest beta values are the negative values of gender (being female) and conscientiousness\n",
    "# that are associated with being a non-user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot illegal drug use vs. largest betas\n",
    "import seaborn as sns\n",
    "sns.scatterplot(x = \"Openness\", y = \"SensationSeeking\", data = data, hue = 'UsedIllegalDrug')\n",
    "plt.savefig('Images/openness_ss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot illegal drug use vs. smallest betas\n",
    "sns.scatterplot(x = \"Female\", y = \"Conscientiousness\", data = data, hue = 'UsedIllegalDrug')\n",
    "plt.savefig('Images/female_c.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score, confusion_matrix\n",
    "y_pred_logreg = logreg.predict(X_train)\n",
    "cm = confusion_matrix(y_train, y_pred_logreg)\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(cm, annot = True, fmt = \".0f\", square = True, annot_kws={\"fontsize\": 50});\n",
    "plt.ylabel('Actual label', fontsize = 20);\n",
    "plt.xlabel('Predicted label', fontsize = 20);\n",
    "score = accuracy_score(y_train, y_pred_logreg).round(2)\n",
    "title = 'Accuracy Score: {0}'.format(score)\n",
    "plt.title(title, size = 20);\n",
    "plt.savefig('Images/cm_logreg.png')\n",
    "plt.show()\n",
    "# 75% accuracy > 64% dummy model\n",
    "# More false negatives than false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other methods of scoring\n",
    "print('===Logistic regression===')\n",
    "print('Accuracy = ', accuracy_score(y_train, y_pred_logreg).round(2))\n",
    "print('Precision =', precision_score(y_train, y_pred_logreg).round(2))\n",
    "print('Recall =', recall_score(y_train, y_pred_logreg).round(2))\n",
    "print('F1 Score =', f1_score(y_train, y_pred_logreg).round(2))\n",
    "print('Balanced accuracy =', balanced_accuracy_score(y_train, y_pred_logreg).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods 2.2 Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(random_state = 20201014)\n",
    "grid = {'max_depth': [None, 1, 5, 10], 'max_features': ['sqrt', None], 'class_weight': ['balanced', None]}\n",
    "gridsearch = GridSearchCV(estimator = dtc, param_grid = grid, n_jobs = -1,                      \n",
    "                          cv = 10, return_train_score = True, scoring = 'balanced_accuracy')\n",
    "gridsearch.fit(X_train, y_train)\n",
    "dtc_models = pd.DataFrame(gridsearch.cv_results_).sort_values('mean_test_score', ascending = False)\n",
    "print('LR mean test score:', round(logreg_models['mean_test_score'].iloc[0], 3))\n",
    "print('LR mest parameters', logreg_models['params'].iloc[0])\n",
    "print('DTC mean test score:', round(dtc_models['mean_test_score'].iloc[0], 3))\n",
    "print('DTC best parameters', dtc_models['params'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with best parameters\n",
    "dtc = DecisionTreeClassifier(class_weight = None, max_depth = 5, max_features = None, \n",
    "                             random_state = 20201014)\n",
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "y_pred_dtc = dtc.predict(X_train)\n",
    "cm = confusion_matrix(y_train, y_pred_dtc)\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(cm, annot = True, fmt = \".0f\", square = True, annot_kws={\"fontsize\": 50});\n",
    "plt.ylabel('Actual label', fontsize = 20);\n",
    "plt.xlabel('Predicted label', fontsize = 20);\n",
    "score = round(accuracy_score(y_train, y_pred_dtc),2)\n",
    "title = 'Accuracy Score: {0}'.format(score)\n",
    "plt.title(title, size = 20);\n",
    "plt.savefig('Images/cm_dtc.png')\n",
    "plt.show()\n",
    "# Better than logistic regression\n",
    "# More false positives than false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other methods of scoring\n",
    "print('===Logistic regression===')\n",
    "print('Accuracy = ', accuracy_score(y_train, y_pred_logreg).round(2))\n",
    "print('Precision =', precision_score(y_train, y_pred_logreg).round(2))\n",
    "print('Recall =', recall_score(y_train, y_pred_logreg).round(2))\n",
    "print('F1 Score =', f1_score(y_train, y_pred_logreg).round(2))\n",
    "print('Balanced accuracy =', balanced_accuracy_score(y_train, y_pred_logreg).round(2))\n",
    "print('===Decision tree classifier===')\n",
    "print('Accuracy = ', accuracy_score(y_train, y_pred_dtc).round(2))\n",
    "print('Precision =', precision_score(y_train, y_pred_dtc).round(2))\n",
    "print('Recall =', recall_score(y_train, y_pred_dtc).round(2))\n",
    "print('F1 Score =', f1_score(y_train, y_pred_dtc).round(2))\n",
    "print('Balanced accuracy =', balanced_accuracy_score(y_train, y_pred_dtc).round(2))\n",
    "# Accuracy is better than logistic regression, but not balanced accuracy, makes sense since scoring = balanced accuracy\n",
    "# and logistic regression had a higher cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tree\n",
    "from sklearn.tree import plot_tree\n",
    "fig = plt.figure(figsize = (100, 20))\n",
    "_ = plot_tree(dtc, \n",
    "                   feature_names = X.columns,  \n",
    "                   class_names = ['Non-user', 'User'],\n",
    "                   filled = True)\n",
    "plt.savefig('Images/tree.png')\n",
    "# Sensation seaking is at the top of the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods 2.3 Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grid search\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# rfc = RandomForestClassifier(random_state = 20201014)\n",
    "# grid = {'max_depth': [None, 1, 5, 10], 'class_weight': ['balanced', None]}\n",
    "# gridsearch = GridSearchCV(estimator = rfc, param_grid = grid, n_jobs = -1,                      \n",
    "#                           cv = 10, return_train_score = True, scoring = 'balanced_accuracy')\n",
    "# gridsearch.fit(X_train, y_train)\n",
    "# rfc_models = pd.DataFrame(gridsearch.cv_results_).sort_values('mean_test_score', ascending = False)\n",
    "# print('LR mean test score:', round(logreg_models['mean_test_score'].iloc[0], 3))\n",
    "# print('LR mest parameters', logreg_models['params'].iloc[0])\n",
    "# print('DTC mean test score:', round(dtc_models['mean_test_score'].iloc[0], 3))\n",
    "# print('DTC best parameters', dtc_models['params'].iloc[0])\n",
    "# print('RFC mean test score:', round(rfc_models['mean_test_score'].iloc[0], 3))\n",
    "# print('RFC best parameters', rfc_models['params'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with best parameters\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(class_weight = 'balanced', max_depth = 5, random_state = 20201014)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Permutation importance](https://scikit-learn.org/dev/auto_examples/inspection/plot_permutation_importance.html) is a good method of ranking random forest features by importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(rfc, X_train, y_train, n_repeats = 10,\n",
    "                                random_state = 20201014, n_jobs = -1)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(result.importances[sorted_idx].T,\n",
    "           vert = False, labels = columns[sorted_idx])\n",
    "ax.set_title(\"Permutation Importances\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "# Again, sensation seeking is the most important feature\n",
    "# Like the logistic regression model, the next three most important featuers are \n",
    "# openness, conscientiousness, and gender (being female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "y_pred_rfc = rfc.predict(X_train)\n",
    "cm = confusion_matrix(y_train, y_pred_rfc)\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(cm, annot = True, fmt = \".0f\", square = True, annot_kws={\"fontsize\": 50});\n",
    "plt.ylabel('Actual label', fontsize = 20);\n",
    "plt.xlabel('Predicted label', fontsize = 20);\n",
    "score = round(accuracy_score(y_train, y_pred_rfc),2)\n",
    "title = 'Accuracy Score: {0}'.format(score)\n",
    "plt.title(title, size = 20);\n",
    "plt.savefig('Images/cm_rfc.png')\n",
    "plt.show()\n",
    "# Better than logistic regression\n",
    "# More false negatives than false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other methods of scoring\n",
    "print('===Logistic regression===')\n",
    "print('Accuracy = ', accuracy_score(y_train, y_pred_logreg).round(2))\n",
    "print('Precision =', precision_score(y_train, y_pred_logreg).round(2))\n",
    "print('Recall =', recall_score(y_train, y_pred_logreg).round(2))\n",
    "print('F1 Score =', f1_score(y_train, y_pred_logreg).round(2))\n",
    "print('Balanced accuracy =', balanced_accuracy_score(y_train, y_pred_logreg).round(2))\n",
    "print('===Decision tree classifier===')\n",
    "print('Accuracy = ', accuracy_score(y_train, y_pred_dtc).round(2))\n",
    "print('Precision =', precision_score(y_train, y_pred_dtc).round(2))\n",
    "print('Recall =', recall_score(y_train, y_pred_dtc).round(2))\n",
    "print('F1 Score =', f1_score(y_train, y_pred_dtc).round(2))\n",
    "print('Balanced accuracy =', balanced_accuracy_score(y_train, y_pred_dtc).round(2))\n",
    "print('===Random forest classifier===')\n",
    "print('Accuracy = ', accuracy_score(y_train, y_pred_rfc).round(2))\n",
    "print('Precision =', precision_score(y_train, y_pred_rfc).round(2))\n",
    "print('Recall =', recall_score(y_train, y_pred_rfc).round(2))\n",
    "print('F1 Score =', f1_score(y_train, y_pred_rfc).round(2))\n",
    "print('Balanced accuracy =', balanced_accuracy_score(y_train, y_pred_rfc).round(2))\n",
    "# Best balanced accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logreg = logreg.predict(X_test)\n",
    "test_dtc = dtc.predict(X_test)\n",
    "test_rfc = rfc.predict(X_test)\n",
    "print('LR Balanced accuracy =', balanced_accuracy_score(y_test, test_logreg).round(3))\n",
    "print('DTC Balanced accuracy =', balanced_accuracy_score(y_test, test_dtc).round(3))\n",
    "print('RFC Balanced accuracy =', balanced_accuracy_score(y_test, test_rfc).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "log_disp = plot_roc_curve(logreg, X_test, y_test)\n",
    "dct_disp = plot_roc_curve(dtc, X_test, y_test, ax = log_disp.ax_)\n",
    "rfc_disp = plot_roc_curve(rfc, X_test, y_test, ax = log_disp.ax_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest classifier has slightly greater balanced accuracy, logistic regression has slighter greater AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and discussion\n",
    "Of the illegal drugs, mushrooms and ecstasy were the most used, heroin and crack were the least used. 64% of participants had used at least one illegal drug. The biggest differences between the group of participants who had used an illegal drug and the group who had never used an illegal drug were that users scored higher on sensation seeking and openness while non-users scored higher on conscientiousness and were older. \n",
    "\n",
    "However, when modeled as a multiple logistic regression, gender (being female) was the largest predictor of being a non-user. In the scatterplots of the largest positive and negative betas, users concentrate in the top right corner of high sensation seeking and openness; in the conscientiousness x gender plot, it appears that males of all conscientiousness levels have used an illegal drug, while there is a cluster of high conscientiousness females who have never used an illegal drug. This may suggest an interaction effect between the conscientiousness and gender features. The logistic regression model predicted illegal drug use with 76% accuracy in the test set, with more false positives for being a user (n = 56) than false negatives for being a non-user (n = 33). \n",
    "\n",
    "The decision tree classifier model was less successful than the logistic regression model with 72% accuracy in the test set. The tree created by the classifier demonstrated that a branch of lower sensation seeking, lower openness, and higher conscientiousness was the most predictive of never using an illegal drug. All other leaves classified an observation as a user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and summary\n",
    "Overall, the results of this project appear to align with published literature and our intuitions of how demographics and personality would impact illegal drug use. Individuals who use an illegal drug in their lifetime tend to be male, score higher on sensation seeking and openness, and lower on conscientiousness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations and later work\n",
    "Given the extremely high usage (~15%) of drugs like heroin and crack, it is clear that the participants of this survey are not representative of the general population. The paper reports that the participants were largely English-speaking, highly educated, and white. Also, because there is no data on the life outcomes of the participants, we cannot conclude that the usage of these illegal drugs is deleterious, and therefore, we cannot conclude that having the associated personality traits is undesirable. \n",
    "\n",
    "In later work with this dataset, I am interested in looking at the drugs individually, and also in groupings other than just illegal drugs. For instance, we know that while mushrooms, ecstasy, cocaine, LSD, ketamine, heroin, and crack are all illegal, it is heroin and crack that are known to be strongly associated with deleterious life outcomes. \n",
    "\n",
    "Below, you will find the preliminary results of an analysis of the totals, percentages, accuracies, intercepts, minimum, and maximum betas for multiple logistic regression models run on each drug individually, with the target variable being \"Used within the last year.\" It is important to note here that the high accuracy metrics for crack and chocolate are not very meaningful, since very few participants and almost all participants used crack and chocolate within the last year, respectively. In these cases of class inbalance, most of the work is accomplished by the intercept value. Measures more sophisticated than accuracy must then be used to evaluate model performance. However, in this preliminary analysis, you can already see that there is differential association of certain drugs with openness, sensation seeking, neuroticism, impulsivity, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv\n",
    "import pandas as pd\n",
    "csv = pd.read_csv('Data/Drugs.csv', header = None)\n",
    "# Name columns\n",
    "columns = ['Age', 'Female', 'Education', 'Country', 'Ethnicity', \\\n",
    "           'Neuroticism', 'Extraversion', 'Openness', 'Agreeableness', 'Conscientiousness', \\\n",
    "           'Impulsivity', 'SensationSeeking', \\\n",
    "           'Alcohol', 'Amphetamines', 'AmylNitrite', 'Benzodiazepines', 'Caffeine', 'Cannabis', 'Chocolate', \\\n",
    "           'Cocaine', 'Crack', 'Ecstasy', 'Heroin', 'Ketamine', 'LegalHighs', 'LSD', 'Methadone', 'Mushrooms', \\\n",
    "           'Nicotine', 'Semer', 'VolatileSubstances']\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame(data = csv)\n",
    "data.columns = columns\n",
    "# Drop multi-category, non-ordinal features\n",
    "data = data.drop(['Country', 'Ethnicity'], axis = 1)\n",
    "# Check value count for Semer, a fictitious drug included to weed out participants responding improperly\n",
    "# Remove these rows\n",
    "data = data[data['Semer'] == 0]\n",
    "# Drop semer column\n",
    "data = data.drop('Semer', axis = 1)\n",
    "# Scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop calculations for each drug\n",
    "drug_name = []\n",
    "total = []\n",
    "percent = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "balanced_accuracy = []\n",
    "f1 = []\n",
    "intercept = []\n",
    "min_beta_name = []\n",
    "min_beta = []\n",
    "max_beta_name = []\n",
    "max_beta = []\n",
    "for i, drug in enumerate(drug_columns):\n",
    "    drug_df = data[data.columns[i + 10]]\n",
    "    drug_df['UsedDrug'] = drug_df > 2 # yearly vs. non-yearly users\n",
    "    # Add column to main data\n",
    "    data['UsedDrug'] = drug_df['UsedDrug']\n",
    "    # Drop columns not of interest\n",
    "    data_drug = data[['Female', 'Education', 'Neuroticism', 'Extraversion', 'Openness', 'Agreeableness', \\\n",
    "                'Conscientiousness', 'Impulsivity', 'SensationSeeking', 'UsedDrug']]\n",
    "    # Separate features from target\n",
    "    X = data_drug.drop('UsedDrug', axis = 1)\n",
    "    y = data_drug['UsedDrug']\n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 20201011)\n",
    "    columns = X_train.columns\n",
    "    # Scale\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    # Run logistic regression\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    coefs = model.coef_.round(2)\n",
    "    # Sort features by beta value\n",
    "    feature_coefs = pd.DataFrame(columns = ['Feature', 'Beta'])\n",
    "    feature_coefs['Feature'] = columns\n",
    "    feature_coefs['Beta'] = coefs[0]\n",
    "    drug_name.append(drug)\n",
    "    total.append(sum(drug_df['UsedDrug']))\n",
    "    percent.append(round(sum(drug_df['UsedDrug'])/len(drug_df['UsedDrug']), 2))\n",
    "    accuracy.append(round(accuracy_score(y_test, y_pred),2))\n",
    "    precision.append(precision_score(y_test, y_pred, zero_division = 0).round(2))\n",
    "    recall.append(recall_score(y_test, y_pred).round(2))\n",
    "    f1.append(f1_score(y_test, y_pred).round(2))\n",
    "    balanced_accuracy.append(balanced_accuracy_score(y_test, y_pred).round(2))\n",
    "    intercept.append(round(model.intercept_[0],2))\n",
    "    min_beta_name.append(feature_coefs.sort_values('Beta').iloc[0][0])\n",
    "    min_beta.append(feature_coefs.sort_values('Beta').iloc[0][1])\n",
    "    max_beta_name.append(feature_coefs.sort_values('Beta', ascending = False).iloc[0][0])\n",
    "    max_beta.append(feature_coefs.sort_values('Beta', ascending = False).iloc[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data frame\n",
    "results = pd.DataFrame({'Drug': drug_name, 'Total': total, 'Percent': percent,\n",
    "                        'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, \\\n",
    "                        'F1 Score': f1, 'Balanced Accuracy': balanced_accuracy, \\\n",
    "                        'Intercept': intercept, \\\n",
    "                        'Min Beta Name': min_beta_name, 'Min Beta': min_beta, \\\n",
    "                        'Max Beta Name': max_beta_name, 'Max Beta': max_beta})\n",
    "results.sort_values('Min Beta')\n",
    "# Accuracy can be high though precision and recall are 0 because classification is totally driven by the intercept\n",
    "# Precision and recall are important when you care about true positions (e.g. crack, heroin) in cases of class inbalance\n",
    "# In opposite cases of class inbalance (user of interest > 90% of sample, e.g. alcohol), \n",
    "# you should care more about true negatives (e.g. correctly classifying Muslims as non-drinkers)\n",
    "# What if you don't model the intercept? LogisticRegression(fit_intercept = False)\n",
    "# Low precision = lots of false positives\n",
    "# If N >> P, F1 is a better metric\n",
    "# If P >> N, balanced accuracy is a better metric"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
